#!/usr/bin/env python3
'''
@Autor: Ana Maria Sandoval Jimenez
'''

from pprint import pprint
import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pylab
import seaborn as sns; sns.set()


import warnings
warnings.filterwarnings("ignore")
###################import pandas_profiling
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.cross_validation import cross_val_score
from sklearn.pipeline import make_pipeline


# load preprocesed train test files
try:
    train = pd.read_csv(sys.argv[1])
    test = pd.read_csv(sys.argv[2])
except IndexError:
    print("usage: linear-reg TRAIN-FILE TEST-FILE")
    sys.exit(1)
                    
#Training a Linear Regression Model
train = train.drop('T2M', axis = 1)

print('Train shape: ', train.shape)
print('Test  shape: ', test.shape)
print(" ")
print('Train columns: ')
pprint(train.columns)
print('Train columns: ')
pprint(test.columns)
# move year as first column in test file
cols = list(test)
if 'Year' in cols:
    # move the column to head of list using index, pop and insert
    cols.insert(0,cols.pop(cols.index('Year')))
    # use ix to reorder
    test = test.ix[:, cols]

print(test.columns)


y = train['mortality_rate']
X = train.drop(['mortality_rate'], axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 101)

lm = LinearRegression()
lm.fit(X_train,y_train)

#Model evaluation
print(lm.intercept_)
coeff_train = pd.DataFrame(lm.coef_,X_train.columns, columns=['Coefficient'])
print(coeff_train)

# Predictions
predictions = lm.predict(X_test)
pred = pd.DataFrame(predictions)
pred.to_csv('pred_2013.csv')
# Metrics
print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

# Model validation via cross-validation
print('Cross validation Score:')
score = cross_val_score(lm, X, y, cv=5)
print(score)
print('CV mean: ', score.mean())

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, mean_squared_error

estimators = LinearRegression()
parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}
grid = GridSearchCV(estimators, parameters, cv=5)
grid.fit(X_train, y_train)
print( "r2 / variance : ", grid.best_score_)
print("Residual sum of squares: %.2f"
              % np.mean((grid.predict(X_test) - y_test) ** 2))


print("Best parameters set found on development set:")
print()
print(grid.best_params_)
print()
print("Grid scores on development set:")
print()
means = grid.cv_results_['mean_test_score']
stds = grid.cv_results_['std_test_score']
for mean, std, params in zip(means, stds, grid.cv_results_['params']):
    print("%0.3f (+/-%0.03f) for %r"
	  % (mean, std * 2, params))
print()

print("Detailed classification report:")
print()
print("The model is trained on the full development set.")
print("The scores are computed on the full evaluation set.")
print()
y_true, y_pred = y_test, grid.predict(X_test)
print(mean_squared_error(y_true, y_pred))
print()


# Predictions for API data
pred = lm.predict(test)

#pred = pd.DataFrame(predictions)
api_results= {
    'Yorkshire and the Humber': pred[0],
    'North West': pred[1],
    'East of England': pred[2],
    'London': pred[3],
    'North East': pred[4],
    'West Midlands': pred[5],
    'East Midlands': pred[6],
    'South West': pred[7],
    'South East': pred[8]
}

import json

data = json.dumps(api_results)
with open('./web/data.js', 'w') as f:
    f.write('data = ' + data)


