#!/usr/bin/env python3
'''
@Autor: Ana Maria Sandoval Jimenez
'''

from pprint import pprint
import sys
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pylab
import seaborn as sns; sns.set()
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings("ignore")

###################import pandas_profiling
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.model_selection import TimeSeriesSplit
from sklearn.cross_validation import cross_val_score

from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline
# load preprocesed train test files
try:
    train = pd.read_csv(sys.argv[1])
    test = pd.read_csv(sys.argv[2])
except IndexError:
    print("usage: linear-reg TRAIN-FILE TEST-FILE")
    sys.exit(1)
                    
#Training a Linear Regression Model
print('Train shape: ', train.shape)
print('Test  shape: ', test.shape)
print(" ")
print('Train columns: ')
pprint(train.columns)
print('Train columns: ')
pprint(test.columns)

y = train['mortality_rate']
X = train.drop(['mortality_rate'], axis=1)
cv_idx = list(TimeSeriesSplit(2).split(X, y))
X_train, X_test, y_train, y_test = X.iloc[cv_idx[0][0], :], X.iloc[cv_idx[0][1],:], y[cv_idx[0][0]], y[cv_idx[0][1]]

lm = LinearRegression()
lm.fit(X_train,y_train)

#Model evaluation
print(lm.intercept_)
coeff_train = pd.DataFrame(lm.coef_,X_train.columns, columns=['Coefficient'])
print(coeff_train)

# Predictions
predictions = lm.predict(X_test)
pred = pd.DataFrame(predictions)

# Metrics
print('MAE:', metrics.mean_absolute_error(y_test, predictions))
print('MSE:', metrics.mean_squared_error(y_test, predictions))
print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predictions)))

# Model validation via cross-validation
print('Cross validation Score:')
score = cross_val_score(lm, X, y, cv=5)
print(score)
print('CV mean: ', score.mean())

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, mean_squared_error

estimators = LinearRegression()
parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}
grid = GridSearchCV(estimators, parameters, cv=5)
grid.fit(X_train, y_train)
print( "r2 / variance : ", grid.best_score_)
print("Residual sum of squares: %.2f"
              % np.mean((grid.predict(X_test) - y_test) ** 2))


print("Best parameters set found on development set:")
print()
print(grid.best_params_)
print()
print("Grid scores on development set:")
print()
means = grid.cv_results_['mean_test_score']
stds = grid.cv_results_['std_test_score']
for mean, std, params in zip(means, stds, grid.cv_results_['params']):
    print("%0.3f (+/-%0.03f) for %r"
	  % (mean, std * 2, params))
print()

print("Detailed classification report:")
print()
print("The model is trained on the full development set.")
print("The scores are computed on the full evaluation set.")
print()
y_true, y_pred = y_test, grid.predict(X_test)
print(mean_squared_error(y_true, y_pred))
print()


# Predictions
predictions = lm.predict(test)
pred = pd.DataFrame(predictions)
pred.to_csv('./out/pred_2013.csv')
# Metrics

